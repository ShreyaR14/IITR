{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imutils in c:\\users\\hp\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (0.5.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.2; however, version 20.2.3 is available.\n",
      "You should consider upgrading via the 'c:\\users\\hp\\appdata\\local\\programs\\python\\python38-32\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Fri Mar 16 14:09:38 2018\n",
    "\n",
    "@author: Aradhya\n",
    "\"\"\"\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Feb 26 00:25:32 2018\n",
    "\n",
    "@author: Admin\n",
    "\"\"\"\n",
    "\n",
    "#using HOG , division of features and then putting SVM\n",
    "#from train.py, windows.py, features.py\n",
    "import numpy as np\n",
    "import cv2\n",
    "from skimage.feature import hog\n",
    "import pickle\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "#from settings import *\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from skimage import exposure\n",
    "from skimage import feature\n",
    "from imutils import paths\n",
    "import argparse\n",
    "import imutils\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#from train1 import *\n",
    "# import support vector classifier\n",
    "from sklearn.svm import LinearSVC# \"Support Vector Classifier\"\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.ndimage.measurements import label\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#from sklearn.metrics import classification\n",
    "#from classification import *\n",
    "#from plot_confusion_matrix1 import *\n",
    "#from confusion_matrix1 import *\n",
    "from scipy.sparse import coo_matrix\n",
    "from scipy.sparse import csr_matrix\n",
    "#from pyimagesearch.helpers import pyramid\n",
    "#from pyimagesearch.helpers import sliding_window\n",
    "\n",
    "#import PIL\n",
    "#from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the following code is for finding HOG using code #1  : features.py\n",
    "def get_hog_features(img, orient, pix_per_cell, cell_per_block, vis=False,transform_sqrt=True, feature_vec=True):\n",
    "\t\"\"\"\n",
    "\tReturn HOG features and visualization (optionally)\n",
    "\t\"\"\"\n",
    "\tif vis == True:\n",
    "\t\tfeatures, hog_image = hog(img, orientations=orient, pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "\t\t\tcells_per_block=(cell_per_block, cell_per_block), transform_sqrt=True,\n",
    "\t\t\tvisualize=True, feature_vector=False)\n",
    "\t\treturn features, hog_image\n",
    "\telse:\n",
    "\t\tfeatures = hog(img, orientations=orient, pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "\t\t\tcells_per_block=(cell_per_block, cell_per_block), transform_sqrt=True,\n",
    "\t\t\tvisualize=False, feature_vector=feature_vec)\n",
    "\t\treturn features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that takes an image,\n",
    "# start and stop positions in both x and y,\n",
    "# window size (x and y dimensions),\n",
    "# and overlap fraction (for both x and y)\n",
    "def slide_window(img, x_start_stop=[None, None], y_start_stop=[None, None],\n",
    "\t\t\t\t\txy_window=(100,84), xy_overlap=(0.5, 0.5)):\n",
    "\t# If x and/or y start/stop positions not defined, set to image size\n",
    "\tif x_start_stop[0] == None:\n",
    "\t\tx_start_stop[0] = 0\n",
    "\tif x_start_stop[1] == None:\n",
    "\t\tx_start_stop[1] = img.shape[1]\n",
    "\tif y_start_stop[0] == None:\n",
    "\t\ty_start_stop[0] = 0\n",
    "\tif y_start_stop[1] == None:\n",
    "\t\ty_start_stop[1] = img.shape[0]\n",
    "\t# Compute the span of the region to be searched\n",
    "\txspan = x_start_stop[1] - x_start_stop[0]\n",
    "\tyspan = y_start_stop[1] - y_start_stop[0]\n",
    "\t# Compute the number of pixels per step in x/y\n",
    "\tnx_pix_per_step = np.int(xy_window[0]*(1 - xy_overlap[0]))\n",
    "\tny_pix_per_step = np.int(xy_window[1]*(1 - xy_overlap[1]))\n",
    "\t# Compute the number of windows in x/y\n",
    "\tnx_windows = np.int(xspan/nx_pix_per_step) - 1\n",
    "\tny_windows = np.int(yspan/ny_pix_per_step) - 1\n",
    "\t# Initialize a list to append window positions to\n",
    "\twindow_list = []\n",
    "\t# Loop through finding x and y window positions\n",
    "\t# Note: you could vectorize this step, but in practice\n",
    "\t# you'll be considering windows one by one with your\n",
    "\t# classifier, so looping makes sense\n",
    "\tfor ys in range(ny_windows):\n",
    "\t\tfor xs in range(nx_windows):\n",
    "\t\t\t# Calculate window position\n",
    "\t\t\tstartx = xs*nx_pix_per_step + x_start_stop[0]\n",
    "\t\t\tendx = startx + xy_window[0]\n",
    "\t\t\tstarty = ys*ny_pix_per_step + y_start_stop[0]\n",
    "\t\t\tendy = starty + xy_window[1]\n",
    "\n",
    "\t\t\t# Append window position to list\n",
    "\t\t\twindow_list.append(((startx, starty), (endx, endy)))\n",
    "\t# Return the list of windows\n",
    "\treturn window_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_space = 'HSV' # Can be RGB, HSV, LUV, HLS, YUV, YCrCb\n",
    "orient = 16  # HOG orientations\n",
    "pix_per_cell = 16 # HOG pixels per cell\n",
    "cell_per_block = 2 # HOG cells per block\n",
    "hog_channel = 0 # Can be 0, 1, 2, or \"ALL\"\n",
    "spatial_size = (32, 32) # Spatial binning dimensions\n",
    "hist_bins = 16    # Number of histogram bins\n",
    "spatial_feat = True # Spatial features on or off\n",
    "hist_feat = True # Histogram features on or off\n",
    "hog_feat = True # HOG features on or off\n",
    "y_start_stop = [300, 500] # Min and max in y to search in slide_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function you will pass an image\n",
    "# and the list of windows to be searched (output of slide_windows())\n",
    "#def search_windows(img, windows, clf, scaler, color_space='RGB',orient=9,pix_per_cell=16, cell_per_block=2):\n",
    "def search_windowfeature(image2,color_space='RGB',orient=9,pix_per_cell=16, cell_per_block=2):       \n",
    "    \n",
    "#    for (x, y, window) in sliding_window(image2, stepSize=32, windowSize=(winW, winH)):            #    on_windows = []  \t#1) Create an empty list to receive positive detection windows\n",
    "#    for window in windows:  #2) Iterate over all windows in the list\n",
    "#        test_img = cv2.resize(img[window[0][1]:window[1][1], window[0][0]:window[1][0]], (100,84))   #3) Extract the test window from original image\n",
    "    # loop over the sliding window for each layer of the pyramid\n",
    "#        if window.shape[0] != winH or window.shape[1] != winW: # if the window does not meet our desired window size, ignore it\n",
    "#            continue\n",
    "        test_img = cv2.cvtColor(window,cv2.COLOR_RGB2GRAY)    \n",
    "        hogfeaturestest, hog_imagetest = get_hog_features(test_img, orient,pix_per_cell, cell_per_block,vis=True,transform_sqrt=True,feature_vec=True,)\n",
    "        featuresizetest=hogfeaturestest.size\n",
    "        hogfeaturestest=np.reshape(hogfeaturestest,(featuresizetest,),order='C')\n",
    "        hogfeaturestest= hogfeaturestest.reshape(1,-1)\t# THIS IS WHERE YOU WOULD PROCESS YOUR WINDOW, SUCH AS APPLYING A\n",
    "        return hogfeaturestest    \n",
    "\n",
    "#        testfeaturesh = X_scaler.transform(hogfeaturestest) \n",
    "#        prediction =svm_model_linear.predict(testfeaturesh) \n",
    "#        if prediction==1:\n",
    "#            on_windows.append(window)\n",
    "#        clone = image2.copy()\n",
    "#        cv2.rectangle(clone, (x, y), (x + winW, y + winH), (0, 255, 0), 2)\n",
    "#        cv2.imshow(\"Window\", clone)\n",
    "#\t\tcv2.waitKey(1)\n",
    "#\t\ttime.sleep(0.025)\n",
    "\t\t#5) Scale extracted features to be fed to classifier\n",
    "#\t\ttest_features = scaler.transform(np.array(features).reshape(1, -1))\n",
    "       \n",
    "\t\t#6) Predict using your classifier\n",
    "#\t\tprediction = clf.predict(test_features)\n",
    "        \n",
    "#        \n",
    "#\t\t#7) If positive (prediction == 1) then save the window\n",
    "#        if prediction == 1:\n",
    "#            on_windows.append(window)\n",
    "#\t#8) Return windows for positive detections\n",
    "#    return on_windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to draw bounding boxes\n",
    "def draw_boxes(img, bboxes, color=(0, 0, 255), thick=2):\n",
    "\t# Make a copy of the image\n",
    "\timcopy = np.copy(img)\n",
    "\t# Iterate through the bounding boxes\n",
    "\tfor bbox in bboxes:\n",
    "\t\t# Draw a rectangle given bbox coordinates\n",
    "\t\tcv2.rectangle(imcopy, bbox[0], bbox[1], color, thick)\n",
    "\t# Return the image copy with boxes drawn\n",
    "\treturn imcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(image, stepSize, windowSize):\n",
    "\t# slide a window across the image\n",
    "\tfor y in range(0, image.shape[0], stepSize):\n",
    "\t\tfor x in range(0, image.shape[1], stepSize):\n",
    "\t\t\t# yield the current window\n",
    "\t\t\tyield (x, y, image[y:y + windowSize[1], x:x + windowSize[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.002120733261108 Seconds to train SVC...\n",
      "Test Accuracy of SVC =  0.8333333333333334\n",
      "confusion matrix is, [[12  0]\n",
      " [ 4  8]]\n",
      "TRP= 0.75\n",
      "FPR= 0.0\n",
      "ACC= 0.8333333333333334\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 1280 features, but this StandardScaler is expecting 720 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-863de28c6dfd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    126\u001b[0m             \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m         \u001b[0mwindowstestfeat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msearch_windowfeature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwindow\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolor_space\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolor_space\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0morient\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpix_per_cell\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpix_per_cell\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcell_per_block\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcell_per_block\u001b[0m\u001b[1;33m)\u001b[0m   \u001b[1;31m# THIS IS WHERE YOU WOULD PROCESS YOUR WINDOW, SUCH AS APPLYING A\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mtestfeaturesh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_scaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwindowstestfeat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m         \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0msvm_model_linear\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestfeaturesh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[0mpred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hp\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X, copy)\u001b[0m\n\u001b[0;32m    789\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    790\u001b[0m         \u001b[0mcopy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopy\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 791\u001b[1;33m         X = self._validate_data(X, reset=False,\n\u001b[0m\u001b[0;32m    792\u001b[0m                                 \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    793\u001b[0m                                 \u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hp\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ensure_2d'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 436\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    437\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hp\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    375\u001b[0m                 )\n\u001b[0;32m    376\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 377\u001b[1;33m                 raise ValueError(\n\u001b[0m\u001b[0;32m    378\u001b[0m                     \u001b[1;34m'X has {} features, but this {} is expecting {} features '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    379\u001b[0m                     'as input.'.format(n_features, self.__class__.__name__,\n",
      "\u001b[1;31mValueError\u001b[0m: X has 1280 features, but this StandardScaler is expecting 720 features as input."
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "#        positive='E:/Ankush Sir Work/PH.D_2017/Code/training/sample_2.JPG'\n",
    "    posfeatures=[]\n",
    "    h1=[]\n",
    "    positive= 'C:/Users/hp/Desktop/Mod1-IITR/fishplate/pos/'\n",
    "    for image_file in os.listdir(positive):\n",
    "        image = mpimg.imread(os.path.join(positive,image_file))\n",
    "#        image = cv2.imread(os.path.join(positive,image_file))\n",
    "#        image = cv2.imread(positive)\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "        gray=np.resize(gray,(100,84))\n",
    "#        gray=gray.reshape((50,50))\n",
    "        \n",
    "#    one method for finding hog............. !!\n",
    "        hogfeatures, hog_image = get_hog_features(gray, orient=9,pix_per_cell=16, cell_per_block=2,vis=True,transform_sqrt=True,feature_vec=True,)\n",
    "        featuresize=hogfeatures.size\n",
    "        hogfeatures=np.reshape(hogfeatures,(featuresize,),order='C')\n",
    "        hogfeatures= hogfeatures.reshape(1,-1)\n",
    "#        fig = plt.figure()\n",
    "#        plt.subplot(121)\n",
    "#        plt.imshow(image)\n",
    "#        plt.title('Example positive Image')\n",
    "#        plt.subplot(122)\n",
    "#        plt.imshow(hog_image, cmap='gray')\n",
    "#        plt.title('HOG Visualization')\n",
    "#        plt.show()\n",
    "        posfeatures.append(hogfeatures)\n",
    "#        tpos=get_hogfeaturesmain(positive)\n",
    "        tpos=np.concatenate(posfeatures)  \n",
    "        h1.append(np.concatenate(posfeatures))\n",
    "\n",
    "#for negative examples\n",
    "    negfeatures=[]\n",
    "    h2=[]\n",
    "    negative= 'C:/Users/hp/Desktop/Mod1-IITR/fishplate/neg/'\n",
    "    for image_file1 in os.listdir(negative):\n",
    "        image1 = mpimg.imread(os.path.join(negative,image_file1))\n",
    "#        image1 = cv2.imread(os.path.join(negative,image_file1))\n",
    "#        image = cv2.imread(positive)\n",
    "        gray1 = cv2.cvtColor(image1, cv2.COLOR_RGB2GRAY)\n",
    "        gray1=np.resize(gray1,(100,84))\n",
    "#        gray=gray.reshape((50,50))\n",
    "        \n",
    "#    one method for finding hog............. !!\n",
    "        hogfeatures1, hog_image1 = get_hog_features(gray1, orient=9,pix_per_cell=16, cell_per_block=2,vis=True,transform_sqrt=True,feature_vec=True,)\n",
    "        featuresize1=hogfeatures1.size\n",
    "        hogfeatures1=np.reshape(hogfeatures1,(featuresize1,),order='C')\n",
    "        hogfeatures1= hogfeatures1.reshape(1,-1)\n",
    "#        fig = plt.figure()\n",
    "#        plt.subplot(121)\n",
    "#        plt.imshow(image)\n",
    "#        plt.title('Example positive Image')\n",
    "#        plt.subplot(122)\n",
    "#        plt.imshow(hog_image, cmap='gray')\n",
    "#        plt.title('HOG Visualization')\n",
    "#        plt.show()\n",
    "        negfeatures.append(hogfeatures1)\n",
    "#        tpos=get_hogfeaturesmain(positive)\n",
    "        t=np.concatenate(negfeatures)  \n",
    "        h2.append(np.concatenate(negfeatures))\n",
    "    \n",
    "#        t1=np.append(negfeatures)               TypeError: append() takes at least 2 arguments (1 given)\n",
    "#        t3=negfeatures.extend(negfeatures)\n",
    "#    h2.append(np.concatenate(negfeatures))    \n",
    "#    \n",
    "#SVM classification \n",
    "svc = LinearSVC()\n",
    "X_scaler = StandardScaler() \n",
    "#train1(tpos,t,svc,X_scaler)\n",
    "#\"\"\"\n",
    "X = np.vstack((tpos,t))\n",
    "\t# Fit a per-column scaler\n",
    "X_scaler.fit(X)\n",
    "\t# Apply the scaler to X\n",
    "scaled_X = X_scaler.transform(X)\n",
    "\n",
    "\t# Define the labels vector\n",
    "y = np.hstack((np.ones(len(tpos)), np.zeros(len(t))))\n",
    "rand_state = np.random.randint(0, 100)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "\t\tscaled_X, y, test_size=0.30, random_state=rand_state)\n",
    "    # Check the training time for the SVC\n",
    "time1=time.time()\n",
    "svm_model_linear=svc.fit(X_train, y_train)\n",
    "#svc.fit(X_train, y_train)\n",
    "t2 = time.time()\n",
    "\n",
    "print(round(t2-time1, 15), 'Seconds to train SVC...')\n",
    "svm_predictions = svm_model_linear.predict(X_test)\n",
    "#svm_predictions = svc.predict(X_test)\n",
    "print('Test Accuracy of SVC = ',svm_model_linear.score(X_test, y_test))  \n",
    "#print('Test Accuracy of SVC = ',svc.score(X_test, y_test))  \n",
    "cm = confusion_matrix(y_test, svm_predictions)\n",
    "print('confusion matrix is,',cm)\n",
    "lentest=len(y_test)\n",
    "tp=float(cm[0,0])\n",
    "fp=float(cm[0,1])\n",
    "fn=float(cm[1,0])\n",
    "tn=float(cm[1,1])\n",
    "tpr=(tp/(tp+fn))\n",
    "   \n",
    "fpr=(fp/(fp+tn))\n",
    "acc=((tp+tn)/lentest)\n",
    "print('TRP=',tpr)\n",
    "print('FPR=',fpr)\n",
    "print('ACC=',acc)\n",
    "\n",
    "#cv2.namedWindow(\"detected\", cv2.WINDOW_NORMAL)    #for fitting the image normally into the window. from TemplateMatching.py\n",
    "# Display predictions on all test_images\n",
    "imdir = 'C:/Users/hp/Desktop/Mod1-IITR/test/'\n",
    "xcord=[]\n",
    "ycord1=[]\n",
    "(winW, winH) = (100,84)\n",
    "for image_file in os.listdir(imdir):\n",
    "    image2 = mpimg.imread(os.path.join(imdir, image_file))\n",
    "    #    image2 = cv2.imread(os.path.join(imdir, image_file))\n",
    "#    image2 = cv2.cvtColor(image2, cv2.COLOR_RGB2GRAY)    \n",
    "#    draw_image1 = np.copy(image2)\n",
    "#    for resized in pyramid(image2, scale=1.5):    # loop over the image pyramid\n",
    "    on_windows=[]\n",
    "    pred=[]\n",
    "    clone = image2.copy()\n",
    "#    hot_windows =search_windowfeature(image2,color_space=color_space,orient=orient, pix_per_cell=pix_per_cell,cell_per_block=cell_per_block) \n",
    "    for (x, y, window) in sliding_window(image2, stepSize=32, windowSize=(winW, winH)):  # loop over the sliding window for each layer of the pyramid\n",
    "        if window.shape[0] != winH or window.shape[1] != winW: # if the window does not meet our desired window size, ignore it\n",
    "            continue\n",
    "        windowstestfeat = search_windowfeature(window,color_space=color_space,orient=orient, pix_per_cell=pix_per_cell,cell_per_block=cell_per_block)  \t# THIS IS WHERE YOU WOULD PROCESS YOUR WINDOW, SUCH AS APPLYING A\n",
    "        testfeaturesh = X_scaler.transform(windowstestfeat) \n",
    "        prediction =svm_model_linear.predict(testfeaturesh) \n",
    "        pred.append(prediction)\n",
    "        if prediction==1:\n",
    "            on_windows.append(window)\n",
    "#            cv2.rectangle(clone, (x, y), (x + winW, y + winH), (0, 255, 0), 2)\n",
    "#            cv2.imshow(\"Window\",clone)\n",
    "#            xcord.append(x)\n",
    "            xcord.append(x)\n",
    "            ycord1.append(y)\n",
    "        cv2.rectangle(clone, (x, y), (x + winW, y + winH), (0, 255, 0), 2)\n",
    "        cv2.imshow(\"Window\",clone)\n",
    "        k=cv2.waitKey(1)\n",
    "#        k = cv2.waitKey(0) & 0xFF\n",
    "#        http://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_gui/py_image_display/py_image_display.html\n",
    "        \n",
    "        time.sleep(0.025)\n",
    "#            x.append(x)\n",
    "#            x.concatenate(x)\n",
    "    \n",
    "#            ty=np.concatenate(y)\n",
    "            \n",
    "#    window_img = draw_boxes(draw_image1,on_windows, color=(0, 0, 255), thick=6)\n",
    "#    plt.imshow(window_img)\n",
    "#    plt.show()    \n",
    "#        cv2.rectangle(draw_image1, (x, y), (x + winW, y + winH), (0, 255, 0), 2)\n",
    "#        cv2.imshow(\"Detected\",draw_image1)\n",
    "#window_img = draw_boxes(image2,hot_windows, color=(0, 0, 255), thick=6)\n",
    "#    plt.imshow(window_img)\n",
    "#    plt.show()\n",
    "#    \n",
    "#    cv2.waitKey(1)\n",
    "#    time.sleep(0.025)\n",
    "           \n",
    "#        windowstestfeat = search_windowfeature(window,color_space=color_space,orient=orient, pix_per_cell=pix_per_cell,cell_per_block=cell_per_block)  \t# THIS IS WHERE YOU WOULD PROCESS YOUR WINDOW, SUCH AS APPLYING A\n",
    "#\t\t# MACHINE LEARNING CLASSIFIER TO CLASSIFY THE CONTENTS OF THE\n",
    "#\t\t# WINDOW\n",
    "#        testfeaturesh = X_scaler.transform(windowstestfeat) \n",
    "#        prediction =svm_model_linear.predict(testfeaturesh) \n",
    "#        if prediction==1:\n",
    "#            cv2.rectangle(draw_image1, (x, y), (x + winW, y + winH), (0, 255, 0), 2)\n",
    "##   return draw_image1 \n",
    "\n",
    "#plt.imshow(draw_image1)\n",
    "#plt.show()\n",
    "#\t\t# since we do not have a classifier, we'll just draw the window\n",
    "#\t\tclone = resized.copy()\n",
    "#\t\tcv2.rectangle(clone, (x, y), (x + winW, y + winH), (0, 255, 0), 2)\n",
    "#\t\tcv2.imshow(\"Window\", clone)\n",
    "#\t\tcv2.waitKey(1)\n",
    "#\t\ttime.sleep(0.025)\n",
    "    \n",
    "\n",
    "\n",
    "## https://github.com/georgesung/vehicle_detection_hog_svm\n",
    "##https://www.pyimagesearch.com/2014/11/10/histogram-oriented-gradients-object-detection/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
